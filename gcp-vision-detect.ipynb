{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This application demonstrates how to perform basic operations with the\\nGoogle Cloud Vision API.\\n\\nExample Usage:\\npython detect.py text ./resources/wakeupcat.jpg\\npython detect.py labels ./resources/landmark.jpg\\npython detect.py web ./resources/landmark.jpg\\npython detect.py web-uri http://wheresgus.com/dog.JPG\\npython detect.py web-geo ./resources/city.jpg\\npython detect.py faces-uri gs://your-bucket/file.jpg\\npython detect.py ocr-uri gs://python-docs-samples-tests/HodgeConj.pdf gs://BUCKET_NAME/PREFIX/\\npython detect.py object-localization ./resources/puppies.jpg\\npython detect.py object-localization-uri gs://...\\n\\nFor more information, the documentation at\\nhttps://cloud.google.com/vision/docs.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2017 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"This application demonstrates how to perform basic operations with the\n",
    "Google Cloud Vision API.\n",
    "\n",
    "Example Usage:\n",
    "python detect.py text ./resources/wakeupcat.jpg\n",
    "python detect.py labels ./resources/landmark.jpg\n",
    "python detect.py web ./resources/landmark.jpg\n",
    "python detect.py web-uri http://wheresgus.com/dog.JPG\n",
    "python detect.py web-geo ./resources/city.jpg\n",
    "python detect.py faces-uri gs://your-bucket/file.jpg\n",
    "python detect.py ocr-uri gs://python-docs-samples-tests/HodgeConj.pdf \\\n",
    "gs://BUCKET_NAME/PREFIX/\n",
    "python detect.py object-localization ./resources/puppies.jpg\n",
    "python detect.py object-localization-uri gs://...\n",
    "\n",
    "For more information, the documentation at\n",
    "https://cloud.google.com/vision/docs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "# [START vision_face_detection]\n",
    "def detect_faces(path):\n",
    "    \"\"\"Detects faces in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_face_detection]\n",
    "    # [START vision_python_migration_image_file]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "    # [END vision_python_migration_image_file]\n",
    "\n",
    "    response = client.face_detection(image=image)\n",
    "    faces = response.face_annotations\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = (\n",
    "        \"UNKNOWN\",\n",
    "        \"VERY_UNLIKELY\",\n",
    "        \"UNLIKELY\",\n",
    "        \"POSSIBLE\",\n",
    "        \"LIKELY\",\n",
    "        \"VERY_LIKELY\",\n",
    "    )\n",
    "    print(\"Faces:\")\n",
    "\n",
    "    for face in faces:\n",
    "        print(f\"anger: {likelihood_name[face.anger_likelihood]}\")\n",
    "        print(f\"joy: {likelihood_name[face.joy_likelihood]}\")\n",
    "        print(f\"surprise: {likelihood_name[face.surprise_likelihood]}\")\n",
    "\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in face.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        print(\"face bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_face_detection]\n",
    "\n",
    "\n",
    "# [END vision_face_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_face_detection_gcs]\n",
    "def detect_faces_uri(uri):\n",
    "    \"\"\"Detects faces in the file located in Google Cloud Storage or the web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    # [START vision_python_migration_image_uri]\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "    # [END vision_python_migration_image_uri]\n",
    "\n",
    "    response = client.face_detection(image=image)\n",
    "    faces = response.face_annotations\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = (\n",
    "        \"UNKNOWN\",\n",
    "        \"VERY_UNLIKELY\",\n",
    "        \"UNLIKELY\",\n",
    "        \"POSSIBLE\",\n",
    "        \"LIKELY\",\n",
    "        \"VERY_LIKELY\",\n",
    "    )\n",
    "    print(\"Faces:\")\n",
    "\n",
    "    for face in faces:\n",
    "        print(f\"anger: {likelihood_name[face.anger_likelihood]}\")\n",
    "        print(f\"joy: {likelihood_name[face.joy_likelihood]}\")\n",
    "        print(f\"surprise: {likelihood_name[face.surprise_likelihood]}\")\n",
    "\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in face.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        print(\"face bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_face_detection_gcs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_label_detection]\n",
    "def detect_labels(path):\n",
    "    \"\"\"Detects labels in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_label_detection]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    print(\"Labels:\")\n",
    "\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_label_detection]\n",
    "\n",
    "\n",
    "# [END vision_label_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_label_detection_gcs]\n",
    "def detect_labels_uri(uri):\n",
    "    \"\"\"Detects labels in the file located in Google Cloud Storage or on the\n",
    "    Web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    print(\"Labels:\")\n",
    "\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_label_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_landmark_detection]\n",
    "def detect_landmarks(path):\n",
    "    \"\"\"Detects landmarks in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_landmark_detection]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.landmark_detection(image=image)\n",
    "    landmarks = response.landmark_annotations\n",
    "    print(\"Landmarks:\")\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        print(landmark.description)\n",
    "        for location in landmark.locations:\n",
    "            lat_lng = location.lat_lng\n",
    "            print(f\"Latitude {lat_lng.latitude}\")\n",
    "            print(f\"Longitude {lat_lng.longitude}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_landmark_detection]\n",
    "\n",
    "\n",
    "# [END vision_landmark_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_landmark_detection_gcs]\n",
    "def detect_landmarks_uri(uri):\n",
    "    \"\"\"Detects landmarks in the file located in Google Cloud Storage or on the\n",
    "    Web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.landmark_detection(image=image)\n",
    "    landmarks = response.landmark_annotations\n",
    "    print(\"Landmarks:\")\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        print(landmark.description)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_landmark_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_logo_detection]\n",
    "def detect_logos(path):\n",
    "    \"\"\"Detects logos in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_logo_detection]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.logo_detection(image=image)\n",
    "    logos = response.logo_annotations\n",
    "    print(\"Logos:\")\n",
    "\n",
    "    for logo in logos:\n",
    "        print(logo.description)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_logo_detection]\n",
    "\n",
    "\n",
    "# [END vision_logo_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_logo_detection_gcs]\n",
    "def detect_logos_uri(uri):\n",
    "    \"\"\"Detects logos in the file located in Google Cloud Storage or on the Web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.logo_detection(image=image)\n",
    "    logos = response.logo_annotations\n",
    "    print(\"Logos:\")\n",
    "\n",
    "    for logo in logos:\n",
    "        print(logo.description)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_logo_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_safe_search_detection]\n",
    "def detect_safe_search(path):\n",
    "    \"\"\"Detects unsafe features in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_safe_search_detection]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.safe_search_detection(image=image)\n",
    "    safe = response.safe_search_annotation\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = (\n",
    "        \"UNKNOWN\",\n",
    "        \"VERY_UNLIKELY\",\n",
    "        \"UNLIKELY\",\n",
    "        \"POSSIBLE\",\n",
    "        \"LIKELY\",\n",
    "        \"VERY_LIKELY\",\n",
    "    )\n",
    "    print(\"Safe search:\")\n",
    "\n",
    "    print(f\"adult: {likelihood_name[safe.adult]}\")\n",
    "    print(f\"medical: {likelihood_name[safe.medical]}\")\n",
    "    print(f\"spoofed: {likelihood_name[safe.spoof]}\")\n",
    "    print(f\"violence: {likelihood_name[safe.violence]}\")\n",
    "    print(f\"racy: {likelihood_name[safe.racy]}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_safe_search_detection]\n",
    "\n",
    "\n",
    "# [END vision_safe_search_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_safe_search_detection_gcs]\n",
    "def detect_safe_search_uri(uri):\n",
    "    \"\"\"Detects unsafe features in the file located in Google Cloud Storage or\n",
    "    on the Web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.safe_search_detection(image=image)\n",
    "    safe = response.safe_search_annotation\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = (\n",
    "        \"UNKNOWN\",\n",
    "        \"VERY_UNLIKELY\",\n",
    "        \"UNLIKELY\",\n",
    "        \"POSSIBLE\",\n",
    "        \"LIKELY\",\n",
    "        \"VERY_LIKELY\",\n",
    "    )\n",
    "    print(\"Safe search:\")\n",
    "\n",
    "    print(f\"adult: {likelihood_name[safe.adult]}\")\n",
    "    print(f\"medical: {likelihood_name[safe.medical]}\")\n",
    "    print(f\"spoofed: {likelihood_name[safe.spoof]}\")\n",
    "    print(f\"violence: {likelihood_name[safe.violence]}\")\n",
    "    print(f\"racy: {likelihood_name[safe.racy]}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_safe_search_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_text_detection]\n",
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_text_detection]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print(\"Texts:\")\n",
    "\n",
    "    for text in texts:\n",
    "        print(f'\\n\"{text.description}\"')\n",
    "\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in text.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        print(\"bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_text_detection]\n",
    "\n",
    "\n",
    "# [END vision_text_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_text_detection_gcs]\n",
    "def detect_text_uri(uri):\n",
    "    \"\"\"Detects text in the file located in Google Cloud Storage or on the Web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print(\"Texts:\")\n",
    "\n",
    "    for text in texts:\n",
    "        print(f'\\n\"{text.description}\"')\n",
    "\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in text.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        print(\"bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_text_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_image_property_detection]\n",
    "def detect_properties(path):\n",
    "    \"\"\"Detects image properties in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_image_properties]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.image_properties(image=image)\n",
    "    props = response.image_properties_annotation\n",
    "    print(\"Properties:\")\n",
    "\n",
    "    for color in props.dominant_colors.colors:\n",
    "        print(f\"fraction: {color.pixel_fraction}\")\n",
    "        print(f\"\\tr: {color.color.red}\")\n",
    "        print(f\"\\tg: {color.color.green}\")\n",
    "        print(f\"\\tb: {color.color.blue}\")\n",
    "        print(f\"\\ta: {color.color.alpha}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_image_properties]\n",
    "\n",
    "\n",
    "# [END vision_image_property_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_image_property_detection_gcs]\n",
    "def detect_properties_uri(uri):\n",
    "    \"\"\"Detects image properties in the file located in Google Cloud Storage or\n",
    "    on the Web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.image_properties(image=image)\n",
    "    props = response.image_properties_annotation\n",
    "    print(\"Properties:\")\n",
    "\n",
    "    for color in props.dominant_colors.colors:\n",
    "        print(f\"frac: {color.pixel_fraction}\")\n",
    "        print(f\"\\tr: {color.color.red}\")\n",
    "        print(f\"\\tg: {color.color.green}\")\n",
    "        print(f\"\\tb: {color.color.blue}\")\n",
    "        print(f\"\\ta: {color.color.alpha}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_image_property_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_web_detection]\n",
    "def detect_web(path):\n",
    "    \"\"\"Detects web annotations given an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_web_detection]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.web_detection(image=image)\n",
    "    annotations = response.web_detection\n",
    "\n",
    "    if annotations.best_guess_labels:\n",
    "        for label in annotations.best_guess_labels:\n",
    "            print(f\"\\nBest guess label: {label.label}\")\n",
    "\n",
    "    if annotations.pages_with_matching_images:\n",
    "        print(\n",
    "            \"\\n{} Pages with matching images found:\".format(\n",
    "                len(annotations.pages_with_matching_images)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for page in annotations.pages_with_matching_images:\n",
    "            print(f\"\\n\\tPage url   : {page.url}\")\n",
    "\n",
    "            if page.full_matching_images:\n",
    "                print(\n",
    "                    \"\\t{} Full Matches found: \".format(len(page.full_matching_images))\n",
    "                )\n",
    "\n",
    "                for image in page.full_matching_images:\n",
    "                    print(f\"\\t\\tImage url  : {image.url}\")\n",
    "\n",
    "            if page.partial_matching_images:\n",
    "                print(\n",
    "                    \"\\t{} Partial Matches found: \".format(\n",
    "                        len(page.partial_matching_images)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for image in page.partial_matching_images:\n",
    "                    print(f\"\\t\\tImage url  : {image.url}\")\n",
    "\n",
    "    if annotations.web_entities:\n",
    "        print(\"\\n{} Web entities found: \".format(len(annotations.web_entities)))\n",
    "\n",
    "        for entity in annotations.web_entities:\n",
    "            print(f\"\\n\\tScore      : {entity.score}\")\n",
    "            print(f\"\\tDescription: {entity.description}\")\n",
    "\n",
    "    if annotations.visually_similar_images:\n",
    "        print(\n",
    "            \"\\n{} visually similar images found:\\n\".format(\n",
    "                len(annotations.visually_similar_images)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for image in annotations.visually_similar_images:\n",
    "            print(f\"\\tImage url    : {image.url}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_web_detection]\n",
    "\n",
    "\n",
    "# [END vision_web_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_web_detection_gcs]\n",
    "def detect_web_uri(uri):\n",
    "    \"\"\"Detects web annotations in the file located in Google Cloud Storage.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.web_detection(image=image)\n",
    "    annotations = response.web_detection\n",
    "\n",
    "    if annotations.best_guess_labels:\n",
    "        for label in annotations.best_guess_labels:\n",
    "            print(f\"\\nBest guess label: {label.label}\")\n",
    "\n",
    "    if annotations.pages_with_matching_images:\n",
    "        print(\n",
    "            \"\\n{} Pages with matching images found:\".format(\n",
    "                len(annotations.pages_with_matching_images)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for page in annotations.pages_with_matching_images:\n",
    "            print(f\"\\n\\tPage url   : {page.url}\")\n",
    "\n",
    "            if page.full_matching_images:\n",
    "                print(\n",
    "                    \"\\t{} Full Matches found: \".format(len(page.full_matching_images))\n",
    "                )\n",
    "\n",
    "                for image in page.full_matching_images:\n",
    "                    print(f\"\\t\\tImage url  : {image.url}\")\n",
    "\n",
    "            if page.partial_matching_images:\n",
    "                print(\n",
    "                    \"\\t{} Partial Matches found: \".format(\n",
    "                        len(page.partial_matching_images)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for image in page.partial_matching_images:\n",
    "                    print(f\"\\t\\tImage url  : {image.url}\")\n",
    "\n",
    "    if annotations.web_entities:\n",
    "        print(\"\\n{} Web entities found: \".format(len(annotations.web_entities)))\n",
    "\n",
    "        for entity in annotations.web_entities:\n",
    "            print(f\"\\n\\tScore      : {entity.score}\")\n",
    "            print(f\"\\tDescription: {entity.description}\")\n",
    "\n",
    "    if annotations.visually_similar_images:\n",
    "        print(\n",
    "            \"\\n{} visually similar images found:\\n\".format(\n",
    "                len(annotations.visually_similar_images)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for image in annotations.visually_similar_images:\n",
    "            print(f\"\\tImage url    : {image.url}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_web_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_web_detection_include_geo]\n",
    "def web_entities_include_geo_results(path):\n",
    "    \"\"\"Detects web annotations given an image, using the geotag metadata\n",
    "    in the image to detect web entities.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    web_detection_params = vision.WebDetectionParams(include_geo_results=True)\n",
    "    image_context = vision.ImageContext(web_detection_params=web_detection_params)\n",
    "\n",
    "    response = client.web_detection(image=image, image_context=image_context)\n",
    "\n",
    "    for entity in response.web_detection.web_entities:\n",
    "        print(f\"\\n\\tScore      : {entity.score}\")\n",
    "        print(f\"\\tDescription: {entity.description}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_web_detection_include_geo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_web_detection_include_geo_gcs]\n",
    "def web_entities_include_geo_results_uri(uri):\n",
    "    \"\"\"Detects web annotations given an image in the file located in\n",
    "    Google Cloud Storage., using the geotag metadata in the image to\n",
    "    detect web entities.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    web_detection_params = vision.WebDetectionParams(include_geo_results=True)\n",
    "    image_context = vision.ImageContext(web_detection_params=web_detection_params)\n",
    "\n",
    "    response = client.web_detection(image=image, image_context=image_context)\n",
    "\n",
    "    for entity in response.web_detection.web_entities:\n",
    "        print(f\"\\n\\tScore      : {entity.score}\")\n",
    "        print(f\"\\tDescription: {entity.description}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_web_detection_include_geo_gcs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_crop_hint_detection]\n",
    "def detect_crop_hints(path):\n",
    "    \"\"\"Detects crop hints in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_crop_hints]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    crop_hints_params = vision.CropHintsParams(aspect_ratios=[1.77])\n",
    "    image_context = vision.ImageContext(crop_hints_params=crop_hints_params)\n",
    "\n",
    "    response = client.crop_hints(image=image, image_context=image_context)\n",
    "    hints = response.crop_hints_annotation.crop_hints\n",
    "\n",
    "    for n, hint in enumerate(hints):\n",
    "        print(f\"\\nCrop Hint: {n}\")\n",
    "\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in hint.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        print(\"bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_crop_hints]\n",
    "\n",
    "\n",
    "# [END vision_crop_hint_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_crop_hint_detection_gcs]\n",
    "def detect_crop_hints_uri(uri):\n",
    "    \"\"\"Detects crop hints in the file located in Google Cloud Storage.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    crop_hints_params = vision.CropHintsParams(aspect_ratios=[1.77])\n",
    "    image_context = vision.ImageContext(crop_hints_params=crop_hints_params)\n",
    "\n",
    "    response = client.crop_hints(image=image, image_context=image_context)\n",
    "    hints = response.crop_hints_annotation.crop_hints\n",
    "\n",
    "    for n, hint in enumerate(hints):\n",
    "        print(f\"\\nCrop Hint: {n}\")\n",
    "\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in hint.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        print(\"bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_crop_hint_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_fulltext_detection]\n",
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START vision_python_migration_document_text_detection]\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                    print(\n",
    "                        \"Word text: {} (confidence: {})\".format(\n",
    "                            word_text, word.confidence\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    for symbol in word.symbols:\n",
    "                        print(\n",
    "                            \"\\tSymbol: {} (confidence: {})\".format(\n",
    "                                symbol.text, symbol.confidence\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    # [END vision_python_migration_document_text_detection]\n",
    "\n",
    "\n",
    "# [END vision_fulltext_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_fulltext_detection_gcs]\n",
    "def detect_document_uri(uri):\n",
    "    \"\"\"Detects document features in the file located in Google Cloud\n",
    "    Storage.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                    print(\n",
    "                        \"Word text: {} (confidence: {})\".format(\n",
    "                            word_text, word.confidence\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    for symbol in word.symbols:\n",
    "                        print(\n",
    "                            \"\\tSymbol: {} (confidence: {})\".format(\n",
    "                                symbol.text, symbol.confidence\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n",
    "\n",
    "# [END vision_fulltext_detection_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_text_detection_pdf_gcs]\n",
    "def async_detect_document(gcs_source_uri, gcs_destination_uri):\n",
    "    \"\"\"OCR with PDF/TIFF as source files on GCS\"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    from google.cloud import vision\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Supported mime_types are: 'application/pdf' and 'image/tiff'\n",
    "    mime_type = \"application/pdf\"\n",
    "\n",
    "    # How many pages should be grouped into each json output file.\n",
    "    batch_size = 2\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    feature = vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "\n",
    "    gcs_source = vision.GcsSource(uri=gcs_source_uri)\n",
    "    input_config = vision.InputConfig(gcs_source=gcs_source, mime_type=mime_type)\n",
    "\n",
    "    gcs_destination = vision.GcsDestination(uri=gcs_destination_uri)\n",
    "    output_config = vision.OutputConfig(\n",
    "        gcs_destination=gcs_destination, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    async_request = vision.AsyncAnnotateFileRequest(\n",
    "        features=[feature], input_config=input_config, output_config=output_config\n",
    "    )\n",
    "\n",
    "    operation = client.async_batch_annotate_files(requests=[async_request])\n",
    "\n",
    "    print(\"Waiting for the operation to finish.\")\n",
    "    operation.result(timeout=420)\n",
    "\n",
    "    # Once the request has completed and the output has been\n",
    "    # written to GCS, we can list all the output files.\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    match = re.match(r\"gs://([^/]+)/(.+)\", gcs_destination_uri)\n",
    "    bucket_name = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # List objects with the given prefix, filtering out folders.\n",
    "    blob_list = [\n",
    "        blob\n",
    "        for blob in list(bucket.list_blobs(prefix=prefix))\n",
    "        if not blob.name.endswith(\"/\")\n",
    "    ]\n",
    "    print(\"Output files:\")\n",
    "    for blob in blob_list:\n",
    "        print(blob.name)\n",
    "\n",
    "    # Process the first output file from GCS.\n",
    "    # Since we specified batch_size=2, the first response contains\n",
    "    # the first two pages of the input file.\n",
    "    output = blob_list[0]\n",
    "\n",
    "    json_string = output.download_as_bytes().decode(\"utf-8\")\n",
    "    response = json.loads(json_string)\n",
    "\n",
    "    # The actual response for the first page of the input file.\n",
    "    first_page_response = response[\"responses\"][0]\n",
    "    annotation = first_page_response[\"fullTextAnnotation\"]\n",
    "\n",
    "    # Here we print the full text from the first page.\n",
    "    # The response contains more information:\n",
    "    # annotation/pages/blocks/paragraphs/words/symbols\n",
    "    # including confidence scores and bounding boxes\n",
    "    print(\"Full text:\\n\")\n",
    "    print(annotation[\"text\"])\n",
    "\n",
    "\n",
    "# [END vision_text_detection_pdf_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_localize_objects]\n",
    "def localize_objects(path):\n",
    "    \"\"\"Localize objects in the local image.\n",
    "\n",
    "    Args:\n",
    "    path: The path to the local file.\n",
    "    \"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    objects = client.object_localization(image=image).localized_object_annotations\n",
    "\n",
    "    print(f\"Number of objects found: {len(objects)}\")\n",
    "    for object_ in objects:\n",
    "        print(f\"\\n{object_.name} (confidence: {object_.score})\")\n",
    "        print(\"Normalized bounding polygon vertices: \")\n",
    "        for vertex in object_.bounding_poly.normalized_vertices:\n",
    "            print(f\" - ({vertex.x}, {vertex.y})\")\n",
    "\n",
    "\n",
    "# [END vision_localize_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_localize_objects_gcs]\n",
    "def localize_objects_uri(uri):\n",
    "    \"\"\"Localize objects in the image on Google Cloud Storage\n",
    "\n",
    "    Args:\n",
    "    uri: The path to the file in Google Cloud Storage (gs://...)\n",
    "    \"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    objects = client.object_localization(image=image).localized_object_annotations\n",
    "\n",
    "    print(f\"Number of objects found: {len(objects)}\")\n",
    "    for object_ in objects:\n",
    "        print(f\"\\n{object_.name} (confidence: {object_.score})\")\n",
    "        print(\"Normalized bounding polygon vertices: \")\n",
    "        for vertex in object_.bounding_poly.normalized_vertices:\n",
    "            print(f\" - ({vertex.x}, {vertex.y})\")\n",
    "\n",
    "\n",
    "# [END vision_localize_objects_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_local(args):\n",
    "    if args.command == \"faces\":\n",
    "        detect_faces(args.path)\n",
    "    elif args.command == \"labels\":\n",
    "        detect_labels(args.path)\n",
    "    elif args.command == \"landmarks\":\n",
    "        detect_landmarks(args.path)\n",
    "    elif args.command == \"text\":\n",
    "        detect_text(args.path)\n",
    "    elif args.command == \"logos\":\n",
    "        detect_logos(args.path)\n",
    "    elif args.command == \"safe-search\":\n",
    "        detect_safe_search(args.path)\n",
    "    elif args.command == \"properties\":\n",
    "        detect_properties(args.path)\n",
    "    elif args.command == \"web\":\n",
    "        detect_web(args.path)\n",
    "    elif args.command == \"crophints\":\n",
    "        detect_crop_hints(args.path)\n",
    "    elif args.command == \"document\":\n",
    "        detect_document(args.path)\n",
    "    elif args.command == \"web-geo\":\n",
    "        web_entities_include_geo_results(args.path)\n",
    "    elif args.command == \"object-localization\":\n",
    "        localize_objects(args.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_uri(args):\n",
    "    if args.command == \"text-uri\":\n",
    "        detect_text_uri(args.uri)\n",
    "    elif args.command == \"faces-uri\":\n",
    "        detect_faces_uri(args.uri)\n",
    "    elif args.command == \"labels-uri\":\n",
    "        detect_labels_uri(args.uri)\n",
    "    elif args.command == \"landmarks-uri\":\n",
    "        detect_landmarks_uri(args.uri)\n",
    "    elif args.command == \"logos-uri\":\n",
    "        detect_logos_uri(args.uri)\n",
    "    elif args.command == \"safe-search-uri\":\n",
    "        detect_safe_search_uri(args.uri)\n",
    "    elif args.command == \"properties-uri\":\n",
    "        detect_properties_uri(args.uri)\n",
    "    elif args.command == \"web-uri\":\n",
    "        detect_web_uri(args.uri)\n",
    "    elif args.command == \"crophints-uri\":\n",
    "        detect_crop_hints_uri(args.uri)\n",
    "    elif args.command == \"document-uri\":\n",
    "        detect_document_uri(args.uri)\n",
    "    elif args.command == \"web-geo-uri\":\n",
    "        web_entities_include_geo_results_uri(args.uri)\n",
    "    elif args.command == \"ocr-uri\":\n",
    "        async_detect_document(args.uri, args.destination_uri)\n",
    "    elif args.command == \"object-localization-uri\":\n",
    "        localize_objects_uri(args.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m parser\u001b[39m.\u001b[39;49mparse_args()\n",
      "File \u001b[1;32mc:\\Users\\hari_\\anaconda3\\envs\\virtualenv_gcp\\Lib\\argparse.py:1872\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1870\u001b[0m \u001b[39mif\u001b[39;00m argv:\n\u001b[0;32m   1871\u001b[0m     msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39munrecognized arguments: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1872\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(msg \u001b[39m%\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(argv))\n\u001b[0;32m   1873\u001b[0m \u001b[39mreturn\u001b[39;00m args\n",
      "File \u001b[1;32mc:\\Users\\hari_\\anaconda3\\envs\\virtualenv_gcp\\Lib\\argparse.py:2630\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2628\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_usage(_sys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m   2629\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[1;32m-> 2630\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
      "File \u001b[1;32mc:\\Users\\hari_\\anaconda3\\envs\\virtualenv_gcp\\Lib\\argparse.py:2617\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2615\u001b[0m \u001b[39mif\u001b[39;00m message:\n\u001b[0;32m   2616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m-> 2617\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             {faces,faces-uri,labels,labels-uri,landmarks,landmarks-uri,text,text-uri,logos,logos-uri,safe-search,safe-search-uri,properties,properties-uri,web,web-uri,web-geo,web-geo-uri,crophints,crophints-uri,document,document-uri,ocr-uri,object-localization,object-localization-uri}\n",
      "                             ...\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9029 --control=9027 --hb=9026 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"67518961-3c54-4bbb-9df1-df797e9a5d63\" --shell=9028 --transport=\"tcp\" --iopub=9030 --f=c:\\Users\\hari_\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-22192UVVXUDUzr1zf.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hari_\\anaconda3\\envs\\virtualenv_gcp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter\n",
    "    )\n",
    "    subparsers = parser.add_subparsers(dest=\"command\")\n",
    "\n",
    "    detect_faces_parser = subparsers.add_parser(\"faces\", help=detect_faces.__doc__)\n",
    "    detect_faces_parser.add_argument(\"path\")\n",
    "\n",
    "    faces_file_parser = subparsers.add_parser(\n",
    "        \"faces-uri\", help=detect_faces_uri.__doc__\n",
    "    )\n",
    "    faces_file_parser.add_argument(\"uri\")\n",
    "\n",
    "    detect_labels_parser = subparsers.add_parser(\"labels\", help=detect_labels.__doc__)\n",
    "    detect_labels_parser.add_argument(\"path\")\n",
    "\n",
    "    labels_file_parser = subparsers.add_parser(\n",
    "        \"labels-uri\", help=detect_labels_uri.__doc__\n",
    "    )\n",
    "    labels_file_parser.add_argument(\"uri\")\n",
    "\n",
    "    detect_landmarks_parser = subparsers.add_parser(\n",
    "        \"landmarks\", help=detect_landmarks.__doc__\n",
    "    )\n",
    "    detect_landmarks_parser.add_argument(\"path\")\n",
    "\n",
    "    landmark_file_parser = subparsers.add_parser(\n",
    "        \"landmarks-uri\", help=detect_landmarks_uri.__doc__\n",
    "    )\n",
    "    landmark_file_parser.add_argument(\"uri\")\n",
    "\n",
    "    detect_text_parser = subparsers.add_parser(\"text\", help=detect_text.__doc__)\n",
    "    detect_text_parser.add_argument(\"path\")\n",
    "\n",
    "    text_file_parser = subparsers.add_parser(\"text-uri\", help=detect_text_uri.__doc__)\n",
    "    text_file_parser.add_argument(\"uri\")\n",
    "\n",
    "    detect_logos_parser = subparsers.add_parser(\"logos\", help=detect_logos.__doc__)\n",
    "    detect_logos_parser.add_argument(\"path\")\n",
    "\n",
    "    logos_file_parser = subparsers.add_parser(\n",
    "        \"logos-uri\", help=detect_logos_uri.__doc__\n",
    "    )\n",
    "    logos_file_parser.add_argument(\"uri\")\n",
    "\n",
    "    safe_search_parser = subparsers.add_parser(\n",
    "        \"safe-search\", help=detect_safe_search.__doc__\n",
    "    )\n",
    "    safe_search_parser.add_argument(\"path\")\n",
    "\n",
    "    safe_search_file_parser = subparsers.add_parser(\n",
    "        \"safe-search-uri\", help=detect_safe_search_uri.__doc__\n",
    "    )\n",
    "    safe_search_file_parser.add_argument(\"uri\")\n",
    "\n",
    "    properties_parser = subparsers.add_parser(\n",
    "        \"properties\", help=detect_properties.__doc__\n",
    "    )\n",
    "    properties_parser.add_argument(\"path\")\n",
    "\n",
    "    properties_file_parser = subparsers.add_parser(\n",
    "        \"properties-uri\", help=detect_properties_uri.__doc__\n",
    "    )\n",
    "    properties_file_parser.add_argument(\"uri\")\n",
    "\n",
    "    # 1.1 Vision features\n",
    "    web_parser = subparsers.add_parser(\"web\", help=detect_web.__doc__)\n",
    "    web_parser.add_argument(\"path\")\n",
    "\n",
    "    web_uri_parser = subparsers.add_parser(\"web-uri\", help=detect_web_uri.__doc__)\n",
    "    web_uri_parser.add_argument(\"uri\")\n",
    "\n",
    "    web_geo_parser = subparsers.add_parser(\n",
    "        \"web-geo\", help=web_entities_include_geo_results.__doc__\n",
    "    )\n",
    "    web_geo_parser.add_argument(\"path\")\n",
    "\n",
    "    web_geo_uri_parser = subparsers.add_parser(\n",
    "        \"web-geo-uri\", help=web_entities_include_geo_results_uri.__doc__\n",
    "    )\n",
    "    web_geo_uri_parser.add_argument(\"uri\")\n",
    "\n",
    "    crop_hints_parser = subparsers.add_parser(\n",
    "        \"crophints\", help=detect_crop_hints.__doc__\n",
    "    )\n",
    "    crop_hints_parser.add_argument(\"path\")\n",
    "\n",
    "    crop_hints_uri_parser = subparsers.add_parser(\n",
    "        \"crophints-uri\", help=detect_crop_hints_uri.__doc__\n",
    "    )\n",
    "    crop_hints_uri_parser.add_argument(\"uri\")\n",
    "\n",
    "    document_parser = subparsers.add_parser(\"document\", help=detect_document.__doc__)\n",
    "    document_parser.add_argument(\"path\")\n",
    "\n",
    "    document_uri_parser = subparsers.add_parser(\n",
    "        \"document-uri\", help=detect_document_uri.__doc__\n",
    "    )\n",
    "    document_uri_parser.add_argument(\"uri\")\n",
    "\n",
    "    ocr_uri_parser = subparsers.add_parser(\n",
    "        \"ocr-uri\", help=async_detect_document.__doc__\n",
    "    )\n",
    "    ocr_uri_parser.add_argument(\"uri\")\n",
    "    ocr_uri_parser.add_argument(\"destination_uri\")\n",
    "\n",
    "    object_localization_parser = subparsers.add_parser(\n",
    "        \"object-localization\", help=async_detect_document.__doc__\n",
    "    )\n",
    "    object_localization_parser.add_argument(\"path\")\n",
    "\n",
    "    object_localization_uri_parser = subparsers.add_parser(\n",
    "        \"object-localization-uri\", help=async_detect_document.__doc__\n",
    "    )\n",
    "    object_localization_uri_parser.add_argument(\"uri\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if \"uri\" in args.command:\n",
    "        run_uri(args)\n",
    "    else:\n",
    "        run_local(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv_gcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
